{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import psycopg2\n",
    "import tensorflow as ts\n",
    "from collections import defaultdict\n",
    "\n",
    "con = psycopg2.connect(database='codeforces', user='Joy')\n",
    "cur = con.cursor()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgres://%s@localhost/%s'%('Joy', 'codeforces'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# create Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# note this is 4x faster than getting it from sql\n",
    "df_smooth = pd.read_csv('user_ratings_smoothed.csv', engine = 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "## calculate difference\n",
    "Only need to run this once\n",
    "```\n",
    "gusr = df_smooth.groupby('handle')\n",
    "stack = []\n",
    "\n",
    "for usr, dfu in gusr:\n",
    "    dfu.is_copy=False\n",
    "    dfu.sort_values('ratingupdatetimeseconds', inplace=True)\n",
    "    stack.append(dfu)\n",
    "\n",
    "df_smooth = pd.concat(stack)\n",
    "for month in range(1, 6):\n",
    "    curr = df_smooth[\"smoothed_%dmonths\" % month]\n",
    "    prev = np.roll(curr, 1)\n",
    "\n",
    "    delta = curr - prev\n",
    "    df_smooth[\"delta_smoothed_%dmonths\" % month] = delta\n",
    "\n",
    "df_smooth.head(50)\n",
    "\n",
    "## output to sql and csv\n",
    "\n",
    "df_smooth.to_csv('user_ratings_smoothed.csv', index=False, header=True)\n",
    "\n",
    "df_smooth.to_sql('user_rating_smooth', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    " **problem type**\n",
    " * contest\n",
    " * virtual\n",
    " * etc\n",
    " \n",
    "**problem info**\n",
    " * tags\n",
    " * rating\n",
    " * point value\n",
    " \n",
    "**submission info**\n",
    " * number of wrong answers\n",
    " * number of TLE\n",
    " * number of compile errors\n",
    " * time between first submission and solve\n",
    " * relative time to competition\n",
    " \n",
    "**user info**\n",
    " * current smooth rating\n",
    " * volatility?\n",
    " * lag can be estimated from user rating and smoothed rating, but do we want it??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting distinct values for categorial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM handles\")\n",
    "all_handles = [h[0] for h in cur.fetchall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run this code **once only** to get a list of keys. This takes ~20 minutes\n",
    "\n",
    "```\n",
    "q = \"\"\"\n",
    "SELECT DISTINCT handle, contestid, problemid FROM submissions;\n",
    "\"\"\"\n",
    "cur.execute(q)\n",
    "keys = cur.fetchall()\n",
    "\n",
    "with open('handle_cid_pid_keys.txt', 'w') as f:\n",
    "    for k in keys:\n",
    "        f.write(','.join(k) + '\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('handle_cid_pid_keys.txt') as f:\n",
    "    keys = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get all tags\n",
    "Only need to run this once:\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT tag FROM tags\n",
    "\"\"\")\n",
    "all_tags = [t[0] for t in cur.fetchall()]\n",
    "\n",
    "df_all_tags = pd.DataFrame(all_tags)\n",
    "df_all_tags.rename_axis({0: 'tag'}, axis=1, inplace=True)\n",
    "df_all_tags.to_sql('all_tags', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT tag FROM all_tags\")\n",
    "all_tags = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get distinct verdicts\n",
    "\n",
    "Only need to run this once:\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT verdict FROM submissions\n",
    "\"\"\")\n",
    "all_verdicts = [v[0] for v in cur.fetchall()]\n",
    "\n",
    "df_all_verdicts = pd.DataFrame(all_verdicts)\n",
    "df_all_verdicts.rename_axis({0: 'verdict'}, axis=1, inplace=True)\n",
    "df_all_verdicts.to_sql('all_verdicts', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT verdict FROM all_verdicts\")\n",
    "all_verdicts = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get distinct participant types\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT participanttype FROM submissions\n",
    "\"\"\")\n",
    "all_participanttypes = [v[0] for v in cur.fetchall()]\n",
    "\n",
    "df_all_participanttypes = pd.DataFrame(all_participanttypes)\n",
    "df_all_participanttypes.rename_axis({0: 'participanttype'}, axis=1, inplace=True)\n",
    "df_all_participanttypes.to_sql('all_participanttypes', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT participanttype FROM all_participanttypes\")\n",
    "all_participanttypes = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### programming languages\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT language FROM submissions\n",
    "\"\"\")\n",
    "all_language = [v[0] for v in cur.fetchall()]\n",
    "\n",
    "df_all_language = pd.DataFrame(all_language)\n",
    "df_all_language.rename_axis({0: 'language'}, axis=1, inplace=True)\n",
    "df_all_language.to_sql('all_language', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT language FROM all_language\")\n",
    "all_language = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem rating and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_prate = pd.read_sql(\"SELECT * FROM problem_rating\", con)\n",
    "df_prate.set_index(['contestid', 'problemid'], inplace=True)\n",
    "\n",
    "df_tags = pd.read_sql(\"SELECT * FROM tags\", con)\n",
    "df_tags.set_index(['contestid', 'problemid'], inplace=True)\n",
    "\n",
    "df_smooth.reset_index(inplace=True)\n",
    "df_smooth.set_index(['handle'], inplace=True)\n",
    "df_smooth.drop('contestname', axis=1, inplace=True)\n",
    "df_smooth.drop('time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_dict = defaultdict(list)\n",
    "keys = [k.split(',') for k in keys]\n",
    "for k in keys:\n",
    "    user_dict[ k[0] ].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "present_handles = set(df_smooth.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "cnt = 0\n",
    "#user = '-----'\n",
    "\n",
    "def getTraining(user):\n",
    "    #filename = 'train_rnn.csv'\n",
    "    filename = 'rnn_train/%s.csv' % user\n",
    "    print filename\n",
    "    trainlist = []\n",
    "    ur = df_smooth.loc[user, :]\n",
    "    if len(ur.shape) == 1:\n",
    "        print \"     Not enough contests for user\", ur.shape\n",
    "        return\n",
    "    #ur.drop(['contestid', 'rank'], inplace=True, axis=1)\n",
    "    ur.is_copy = False\n",
    "    ur.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    for k in user_dict[user]:\n",
    "        q = \"\"\"\n",
    "        SELECT * FROM submissions\n",
    "            WHERE\n",
    "                handle = '%s'\n",
    "                AND\n",
    "                contestid = '%s'\n",
    "                AND\n",
    "                problemid = '%s'\n",
    "        \"\"\" % (k[0], k[1], k[2])\n",
    "\n",
    "        df = pd.read_sql(q, con)\n",
    "        df.is_copy = False\n",
    "\n",
    "        ex = dict()\n",
    "        \n",
    "        # generic problem info\n",
    "        ex['points'] = df.points[0]\n",
    "        ex['starttimeseconds'] = min(df.starttimeseconds)\n",
    "        ex['stoptimeseconds'] = max(df.starttimeseconds)\n",
    "        \n",
    "        # user rating info ----------------------------------\n",
    "        # find closest next contest\n",
    "        # if there is no next contest,then skip this entry\n",
    "        idx = ur.ratingupdatetimeseconds >= ex['stoptimeseconds']\n",
    "        if not np.any(idx):\n",
    "            continue\n",
    "        tur = ur.loc[idx]\n",
    "        tur.is_copy = False\n",
    "        idx = tur.ratingupdatetimeseconds == min(tur.ratingupdatetimeseconds)\n",
    "        tur = tur.loc[idx].to_dict(orient='records')[0]\n",
    "        ex.update(tur)\n",
    "\n",
    "\n",
    "        # verdicts\n",
    "        vcnt = df.verdict.value_counts()\n",
    "        vdict = vcnt.to_dict()\n",
    "        ex.update(vdict)\n",
    "\n",
    "        # participant type\n",
    "        pcnt = df.participanttype.value_counts()\n",
    "        pdict = pcnt.to_dict()\n",
    "        for t in pdict.iterkeys():\n",
    "            ex[t] = 1\n",
    "\n",
    "        # language\n",
    "        lcnt = df.language.value_counts()\n",
    "        ldict = lcnt.to_dict()\n",
    "        ex.update(ldict)\n",
    "\n",
    "        # problem rating\n",
    "        if (k[1], k[2]) in df_prate.index:\n",
    "            ex['problem_rating'] = df_prate.loc[str(k[1]),str(k[2])].values[0]\n",
    "        else:\n",
    "            ex['problem_rating'] = -1\n",
    "\n",
    "        # time to solves\n",
    "        solvetime = df.loc[df.verdict=='OK', 'starttimeseconds']\n",
    "        if len(solvetime) > 0:\n",
    "            ex['solvetimeseconds'] = min(solvetime)\n",
    "        else:\n",
    "            ex['solvetimeseconds'] = -1\n",
    "\n",
    "        trainlist.append(ex)\n",
    "\n",
    "    df_train = pd.DataFrame.from_dict(trainlist)\n",
    "    for t in all_tags:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "    for t in all_verdicts:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "    for t in all_participanttypes:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "    for t in all_language:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "            \n",
    "    df_train.to_csv(filename, mode='w', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import generate_features_RNN as gfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binvars = gfr.get_categorical_variables([\n",
    "    'all_participanttypes',\n",
    "    'all_tags',\n",
    "    'all_language'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_train/tourist.csv\n"
     ]
    }
   ],
   "source": [
    "reload(gfr)\n",
    "lastidx = 0 \n",
    "user = 'tourist'\n",
    "user_rating = df_smooth.loc[user, :]\n",
    "gfr.getTraining(user, user_rating, df_prate, user_dict[user], binvars, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('rnn_train/tourist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastidx = 0\n",
    "for i, user in enumerate(all_handles[lastidx:]):\n",
    "    if user in present_handles:\n",
    "        print lastidx + i, user\n",
    "        getTraining(user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
