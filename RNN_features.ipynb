{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import psycopg2\n",
    "import tensorflow as ts\n",
    "from collections import defaultdict\n",
    "\n",
    "con = psycopg2.connect(database='codeforces', user='Joy')\n",
    "cur = con.cursor()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgres://%s@localhost/%s'%('Joy', 'codeforces'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# create Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# note this is 4x faster than getting it from sql\n",
    "df_smooth = pd.read_csv('user_ratings_smoothed.csv', engine = 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "## calculate difference\n",
    "Only need to run this once\n",
    "```\n",
    "gusr = df_smooth.groupby('handle')\n",
    "stack = []\n",
    "\n",
    "for usr, dfu in gusr:\n",
    "    dfu.is_copy=False\n",
    "    dfu.sort_values('ratingupdatetimeseconds', inplace=True)\n",
    "    stack.append(dfu)\n",
    "\n",
    "df_smooth = pd.concat(stack)\n",
    "for month in range(1, 6):\n",
    "    curr = df_smooth[\"smoothed_%dmonths\" % month]\n",
    "    prev = np.roll(curr, 1)\n",
    "\n",
    "    delta = curr - prev\n",
    "    df_smooth[\"delta_smoothed_%dmonths\" % month] = delta\n",
    "\n",
    "df_smooth.head(50)\n",
    "\n",
    "## output to sql and csv\n",
    "\n",
    "df_smooth.to_csv('user_ratings_smoothed.csv', index=False, header=True)\n",
    "\n",
    "df_smooth.to_sql('user_rating_smooth', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    " **problem type**\n",
    " * contest\n",
    " * virtual\n",
    " * etc\n",
    " \n",
    "**problem info**\n",
    " * tags\n",
    " * rating\n",
    " * point value\n",
    " \n",
    "**submission info**\n",
    " * number of wrong answers\n",
    " * number of TLE\n",
    " * number of compile errors\n",
    " * time between first submission and solve\n",
    " * relative time to competition\n",
    " \n",
    "**user info**\n",
    " * current smooth rating\n",
    " * volatility?\n",
    " * lag can be estimated from user rating and smoothed rating, but do we want it??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting distinct values for categorial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM handles\")\n",
    "all_handles = [h[0] for h in cur.fetchall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run this code **once only** to get a list of keys. This takes ~20 minutes\n",
    "\n",
    "```\n",
    "q = \"\"\"\n",
    "SELECT DISTINCT handle, contestid, problemid FROM submissions;\n",
    "\"\"\"\n",
    "cur.execute(q)\n",
    "keys = cur.fetchall()\n",
    "\n",
    "with open('handle_cid_pid_keys.txt', 'w') as f:\n",
    "    for k in keys:\n",
    "        f.write(','.join(k) + '\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('handle_cid_pid_keys.txt') as f:\n",
    "    keys = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get all tags\n",
    "Only need to run this once:\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT tag FROM tags\n",
    "\"\"\")\n",
    "all_tags = [t[0] for t in cur.fetchall()]\n",
    "\n",
    "df_all_tags = pd.DataFrame(all_tags)\n",
    "df_all_tags.rename_axis({0: 'tag'}, axis=1, inplace=True)\n",
    "df_all_tags.to_sql('all_tags', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT tag FROM all_tags\")\n",
    "all_tags = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get distinct verdicts\n",
    "\n",
    "Only need to run this once:\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT verdict FROM submissions\n",
    "\"\"\")\n",
    "all_verdicts = [v[0] for v in cur.fetchall()]\n",
    "\n",
    "df_all_verdicts = pd.DataFrame(all_verdicts)\n",
    "df_all_verdicts.rename_axis({0: 'verdict'}, axis=1, inplace=True)\n",
    "df_all_verdicts.to_sql('all_verdicts', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT verdict FROM all_verdicts\")\n",
    "all_verdicts = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get distinct participant types\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT participanttype FROM submissions\n",
    "\"\"\")\n",
    "all_participanttypes = [v[0] for v in cur.fetchall()]\n",
    "\n",
    "df_all_participanttypes = pd.DataFrame(all_participanttypes)\n",
    "df_all_participanttypes.rename_axis({0: 'participanttype'}, axis=1, inplace=True)\n",
    "df_all_participanttypes.to_sql('all_participanttypes', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT participanttype FROM all_participanttypes\")\n",
    "all_participanttypes = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### programming languages\n",
    "```\n",
    "cur.execute(\"\"\"\n",
    "SELECT DISTINCT language FROM submissions\n",
    "\"\"\")\n",
    "all_language = [v[0] for v in cur.fetchall()]\n",
    "\n",
    "df_all_language = pd.DataFrame(all_language)\n",
    "df_all_language.rename_axis({0: 'language'}, axis=1, inplace=True)\n",
    "df_all_language.to_sql('all_language', engine, if_exists='replace')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT language FROM all_language\")\n",
    "all_language = set([t[0] for t in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem rating and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_prate = pd.read_sql(\"SELECT * FROM problem_rating\", con)\n",
    "df_prate.set_index(['contestid', 'problemid'], inplace=True)\n",
    "\n",
    "df_tags = pd.read_sql(\"SELECT * FROM tags\", con)\n",
    "df_tags.set_index(['contestid', 'problemid'], inplace=True)\n",
    "\n",
    "df_smooth.reset_index(inplace=True)\n",
    "df_smooth.set_index(['handle'], inplace=True)\n",
    "df_smooth.drop('contestname', axis=1, inplace=True)\n",
    "df_smooth.drop('time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_dict = defaultdict(list)\n",
    "keys = [k.split(',') for k in keys]\n",
    "for k in keys:\n",
    "    user_dict[ k[0] ].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "present_handles = set(df_smooth.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "cnt = 0\n",
    "#user = '-----'\n",
    "\n",
    "def getTraining(user):\n",
    "    #filename = 'train_rnn.csv'\n",
    "    filename = 'rnn_train/%s.csv' % user\n",
    "    print filename\n",
    "    trainlist = []\n",
    "    ur = df_smooth.loc[user, :]\n",
    "    if len(ur.shape) == 1:\n",
    "        print \"     Not enough contests for user\", ur.shape\n",
    "        return\n",
    "    #ur.drop(['contestid', 'rank'], inplace=True, axis=1)\n",
    "    ur.is_copy = False\n",
    "    ur.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    for k in user_dict[user]:\n",
    "        q = \"\"\"\n",
    "        SELECT * FROM submissions\n",
    "            WHERE\n",
    "                handle = '%s'\n",
    "                AND\n",
    "                contestid = '%s'\n",
    "                AND\n",
    "                problemid = '%s'\n",
    "        \"\"\" % (k[0], k[1], k[2])\n",
    "\n",
    "        df = pd.read_sql(q, con)\n",
    "        df.is_copy = False\n",
    "\n",
    "        ex = dict()\n",
    "        \n",
    "        # generic problem info\n",
    "        ex['points'] = df.points[0]\n",
    "        ex['starttimeseconds'] = min(df.starttimeseconds)\n",
    "        ex['stoptimeseconds'] = max(df.starttimeseconds)\n",
    "        \n",
    "        # user rating info ----------------------------------\n",
    "        # find closest next contest\n",
    "        # if there is no next contest,then skip this entry\n",
    "        idx = ur.ratingupdatetimeseconds >= ex['stoptimeseconds']\n",
    "        if not np.any(idx):\n",
    "            continue\n",
    "        tur = ur.loc[idx]\n",
    "        tur.is_copy = False\n",
    "        idx = tur.ratingupdatetimeseconds == min(tur.ratingupdatetimeseconds)\n",
    "        tur = tur.loc[idx].to_dict(orient='records')[0]\n",
    "        ex.update(tur)\n",
    "\n",
    "\n",
    "        # verdicts\n",
    "        vcnt = df.verdict.value_counts()\n",
    "        vdict = vcnt.to_dict()\n",
    "        ex.update(vdict)\n",
    "\n",
    "        # participant type\n",
    "        pcnt = df.participanttype.value_counts()\n",
    "        pdict = pcnt.to_dict()\n",
    "        for t in pdict.iterkeys():\n",
    "            ex[t] = 1\n",
    "\n",
    "        # language\n",
    "        lcnt = df.language.value_counts()\n",
    "        ldict = lcnt.to_dict()\n",
    "        ex.update(ldict)\n",
    "\n",
    "        # problem rating\n",
    "        if (k[1], k[2]) in df_prate.index:\n",
    "            ex['problem_rating'] = df_prate.loc[str(k[1]),str(k[2])].values[0]\n",
    "        else:\n",
    "            ex['problem_rating'] = -1\n",
    "\n",
    "        # time to solves\n",
    "        solvetime = df.loc[df.verdict=='OK', 'starttimeseconds']\n",
    "        if len(solvetime) > 0:\n",
    "            ex['solvetimeseconds'] = min(solvetime)\n",
    "        else:\n",
    "            ex['solvetimeseconds'] = -1\n",
    "\n",
    "        trainlist.append(ex)\n",
    "\n",
    "    df_train = pd.DataFrame.from_dict(trainlist)\n",
    "    for t in all_tags:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "    for t in all_verdicts:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "    for t in all_participanttypes:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "    for t in all_language:\n",
    "        if t not in df_train.columns:\n",
    "            df_train[t] = np.nan\n",
    "            \n",
    "#    if df_train.shape[1] != 100:\n",
    "#        print df_train.columns\n",
    "\n",
    "#    if exists(filename):\n",
    "    df_train.to_csv(filename, mode='w', index=False, header=True)\n",
    "#    else:\n",
    "#        df_train.to_csv(filename, mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import generate_features_RNN as gfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "binvars = gfr.get_categorical_variables([\n",
    "    'all_participanttypes',\n",
    "    'all_tags',\n",
    "    'all_language'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_train/tourist.csv\n"
     ]
    }
   ],
   "source": [
    "reload(gfr)\n",
    "lastidx = 0 \n",
    "user = 'tourist'\n",
    "user_rating = df_smooth.loc[user, :]\n",
    "gfr.getTraining(user, user_rating, df_prate, user_dict[user], binvars, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('rnn_train/tourist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       97\n",
       "1       10\n",
       "2       10\n",
       "3       13\n",
       "4       13\n",
       "5      512\n",
       "6      316\n",
       "7      316\n",
       "8      316\n",
       "9      316\n",
       "10     316\n",
       "11     316\n",
       "12     316\n",
       "13     316\n",
       "14     316\n",
       "15     316\n",
       "16     356\n",
       "17     356\n",
       "18     356\n",
       "19     356\n",
       "20     356\n",
       "21     356\n",
       "22     356\n",
       "23     356\n",
       "24     356\n",
       "25     356\n",
       "26     356\n",
       "27     356\n",
       "28     356\n",
       "29     367\n",
       "      ... \n",
       "904     83\n",
       "905     83\n",
       "906     83\n",
       "907     83\n",
       "908     83\n",
       "909     85\n",
       "910     85\n",
       "911     85\n",
       "912     85\n",
       "913     85\n",
       "914     86\n",
       "915     87\n",
       "916     87\n",
       "917     86\n",
       "918     86\n",
       "919     87\n",
       "920     87\n",
       "921     87\n",
       "922     87\n",
       "923     87\n",
       "924     89\n",
       "925     89\n",
       "926     89\n",
       "927     89\n",
       "928     89\n",
       "929     97\n",
       "930     97\n",
       "931     97\n",
       "932     97\n",
       "933    101\n",
       "Name: contestid, Length: 934, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.contestid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tourist\n",
      "rnn_train/tourist.csv\n",
      "1 LHiC\n",
      "rnn_train/LHiC.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-5d6661dc9793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpresent_handles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mlastidx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mgetTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-b4c0978c9200>\u001b[0m in \u001b[0;36mgetTraining\u001b[0;34m(user)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\" % (k[0], k[1], k[2])\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             chunksize=chunksize)\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1451\u001b[0m             frame = _wrap_result(data, columns, index_col=index_col,\n\u001b[1;32m   1452\u001b[0m                                  \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                  parse_dates=parse_dates)\n\u001b[0m\u001b[1;32m   1454\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(data, columns, index_col, coerce_float, parse_dates)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     frame = DataFrame.from_records(data, columns=columns,\n\u001b[0;32m--> 157\u001b[0;31m                                    coerce_float=coerce_float)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0m_parse_date_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mfrom_records\u001b[0;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5500\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5501\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5503\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5810\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5811\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 5812\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   5813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5814\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2950\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2951\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2952\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path)\u001b[0m\n\u001b[1;32m   2917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2919\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/dtypes/cast.pyc\u001b[0m in \u001b[0;36mmaybe_cast_to_datetime\u001b[0;34m(value, dtype, errors)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0mnan\u001b[0m \u001b[0mto\u001b[0m \u001b[0miNaT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m     \"\"\"\n\u001b[0;32m--> 872\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedeltas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_timedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lastidx = 0\n",
    "for i, user in enumerate(all_handles[lastidx:]):\n",
    "    if user in present_handles:\n",
    "        print lastidx + i, user\n",
    "        getTraining(user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
